{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Uvod u neuronske mreže, graf izračunavanja\n",
    "\n",
    "Uvodni materijal u vidu 3 video tutorijala se nalazi na https://www.youtube.com/playlist?list=PLBI8Ys-vopqbbP-XIj_L2BCdsWGxHxSSh. Dalji materijal vežbi podrazumeva posedovanje znanja sa uvodnog materijala.\n",
    "\n",
    "Dodatna objašnjenja za neuronske mreže i backpropagation se mogu naći u tutorijalu koje je napravio Andrej Karpathy https://www.youtube.com/watch?v=VMj-3S1tku0\n",
    "\n",
    "---\n",
    "\n",
    "## Veštački neuron\n",
    "\n",
    "Model veštačkog neurona sastoji se od:\n",
    "* **n ulaza**, gde je svaki ulaz skalar, odnosno realan broj\n",
    "* **bias**, ulaz koji je zadat implicitno i čija vrednost je uvek 1.\n",
    "* **n + 1 težina**, n za svaki ulaz + 1 za bias, težine su isto skalari, tj. realni brojevi\n",
    "* **n + 1 množača**, za množenje svakog ulaza (i biasa) njemu odgovarajućom težinom\n",
    "* **sabirač**, za sumu ponderisanih ulaza i biasa\n",
    "* **aktivaciona funkcija**, čiji ulaz je rezultat sabirača, i uglavnom je ova funkcija neka nelinearna funkcija\n",
    "\n",
    "\n",
    "![img/artificial_neuron.png](img/artificial_neuron.png)\n",
    "\n",
    "Pošto ćemo veštački neuron implementirati kao graf izračunavanja, za početak potrebno je implementirati 3 čvora izračunavanja:\n",
    "* množač\n",
    "* sabirač\n",
    "* sigmoidalnu funkciju (koja će biti aktivaciona funkcija)\n",
    "\n",
    "Iako se graf i čvorovi izračunavanja koriste u i opštijem smislu, radi jednostavnosti implementacije uvešćemo par ograničenja za ova 3 čvora izračunavanja:\n",
    "* množač: treba da ima **samo dva ulaza**, jer ćemo njega koristiti za množenje isključivo nekog konkretnog ulaza u neuron i njegove težine\n",
    "* sabirač: treba da ima **prozivoljan broj ulaza**, jer ćemo sumirati sve ponderisane ulaze u neuron, koliko god da ih ima\n",
    "* sigmoidalna funkcija: treba da im **jedan ulaz**, jer ćemo je koristiti isključivo nad skalarom, odnosno rezultatom iz sabirača\n",
    "\n",
    "#### Zadaci\n",
    "\n",
    "**TODO 1:** Implementirati forward-pass i backward-pass za množač, ```MultiplyNode```.\n",
    "\n",
    "**TODO 2:** Implementirati forward-pass i backward-pass za sabirač, ```SumNode```.\n",
    "\n",
    "**TODO 3:** Implementirati forward-pass i backward-pass za sigmoidalnu funkciju, ```SigmoidNode```.\n",
    "\n",
    "Ukoliko ste sve iz prethodna 3 zadatka implementirali kako treba, videćete na konzoli ispis:\n",
    "\n",
    "```\n",
    "MultiplyNode: tests passed\n",
    "SumNode: tests passed\n",
    "SigmoidNode: tests passed\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**TODO 4, 5, 6:** Konstruisati veštački neuron (klasa ```NeuronNode```) kao graf izračunavanja, korišćenjem množača, sabirača i aktivacione funkcije.\n",
    "\n",
    "**TODO 7:** Implementirati forward-pass za neuron.\n",
    "\n",
    "**TODO 8:** Implementirati backward-pass za neuron.\n",
    "\n",
    "---\n",
    "\n",
    "## Sloj veštačkih neurona\n",
    "\n",
    "Više veštačkih neurona se mogu kombinovati u tzv. slojeve. Ograničenja prilikom pravljenja sloja neurona su:\n",
    "* svi neuroni u sloju moraju imati isti broj ulaza\n",
    "* svi neuroni u sloju moraju imati istu aktivacionu funkciju\n",
    "\n",
    "Sloj neurona ima onoliko izlaza koliko i ima neurona u sebi.\n",
    "\n",
    "![img/layer.png](img/layer.png)\n",
    "\n",
    "**Pogledati klasu ```NeuralLayer``` za detalje o implementaciji sloja veštačkih neurona**\n",
    "\n",
    "---\n",
    "\n",
    "## Veštačka neuronska mreža\n",
    "\n",
    "Više slojeva neurona mogu se kombinovati u kompletnu veštačku neuronsku mrežu. Ukoliko mreža ima **N ulaza** i **M izlaza**, to znači da prvi sloj (ulazni sloj) neuronske mreže mora imati tačno N ulaza, i da poslednji sloj (izlazni sloj) mora imati M izlaza.\n",
    "\n",
    "Neuronska mreža može imati proizvoljan broj skrivenih slojeva. Ulaz za svaki skriveni sloj je izlaz iz prethodnog sloja.\n",
    "\n",
    "![img/network.jpg](img/network.jpg)\n",
    "\n",
    "\n",
    "#### Zadaci\n",
    "\n",
    "**TODO 9:** Implementirati forward-pass za celu neuronsku mrežu.\n",
    "\n",
    "**TODO 10:** Implementirati backward-pass za celu neuronsku mrežu.\n",
    "\n",
    "---\n",
    "\n",
    "### Obučavanje veštačke neuronske mreže\n",
    "\n",
    "Za obučavanje neuronske mreže koristi se algoritam optimizacije prvog reda, odnosno algoritam opadajućeg gradijenta (*eng. gradient descent*). Kao funkciju greške koristićemo kvadratnu grešku.\n",
    "\n",
    "Kako bismo obučili neuronsku mrežu, neophodno je spremiti **ulaze** i **željene izlaze**, ovaj skup uređenih parova ulaza i željenih izlaz se naziva **obučavajući skup**.\n",
    "\n",
    "Odnosno, ako neuronsku mrežu posmatramo kao crnu kutiju, ona treba da nauči funkciju $ y = f(x_1, x_2, ..., x_n) $. Dakle, za zadate ulaze *x*, mreža treba da nauči kako da proizvede željeni izlaz *y*. Pa kako to neuronska mreža radi? Pa jednostavno - **optmimizacijom težina svojih neurona**!\n",
    "\n",
    "Formalno, treba minimizovati funkciju greške $ E(W) $, gde *W* predstavlja **parametre** veštačke neuronske mreže, a ti **parametri su zapravo težine neurona**.\n",
    "\n",
    "Dakle, za svaki uzorak iz svog obučavajućeg skupa:\n",
    "1. izračunati izlaz iz neuronske mreže (forward-pass)\n",
    "2. izračunati vrednost funkcije greške na osnovu izračunatog i željenog izlaza \n",
    "3. izračunati gradijent funkcije greške u odnosu na izlaz\n",
    "4. propagirati unazad (**backopropagation**) gradijent i računati gradijent težina svakog neurona (backward-pass)\n",
    "5. ažurirati težine neurona korišćenjem algoritma opadajućeg gradijenta, odnosno za svaku težinu $ w = w - \\alpha*\\frac{\\delta E}{\\delta w} $\n",
    "\n",
    "*Gorenavedeni postupak iterativno ponavljati zadati broj iteracija/epoha (```nb_epochs```).* Tokom obučavanja bi vrednost funkcije greške trebala da konvergira ka minimumu.\n",
    "\n",
    "**TODO 11:** Implementirati ažuriranje težina veštačkog neurona na osnovu izračunatog gradijenta (tokom backward-pass) i koraka koji je zadat kroz parametar ```learning_rate```.\n",
    "\n",
    "---\n",
    "\n",
    "**TODO 12:** Konstruisati neuronsku mrežu koja rešava XOR problem.\n",
    "\n",
    "---\n",
    "\n",
    "**TODO (dodatno):** Dodati **linearnu** aktivacionu funkciju, ```lin(x) = x```.\n",
    "\n",
    "**TODO (dodatno):** Dodati **ReLU** aktivacionu funkciju, ```relu(x) = max(0, x)```.\n",
    "\n",
    "**TODO (dodatno):** Proširiti ažuriranje težina parametrom ```momentum```. Ovaj parametar predstavlja momemat gradijenta, odnosno vrednost promene težine iz prethodne iteracije, što se može iskoristiti za znatno ubrzavanje obučavanje neuronske mreže. Odnosno, težine se sad ažuriraju po formuli $ w = w - (\\alpha*\\frac{\\delta E}{\\delta w} + \\mu*\\Delta w )$. Tipična vrednosta za ovaj parametar je ```momentum = 0.9```.\n",
    "\n",
    "---\n",
    "\n",
    "#### DODATNO\n",
    "\n",
    "* Konstruisati i obučiti neuronsku mrežu na problemu određivanja da li se unutar prostorije nalazi neka osoba (Occupancy), ako su dati: vlažnost vazduha u prostoriji (Humidity), količina svetla u prostoriji (Light), količina CO2 u prostoriji (CO2), odnos težine vodene pare i ukupnog vazduha (HumidityRatio). Podaci za obučavanje se nalaze u ```data/occupancy_train.csv```. Obučenu neuronsku mrežu validirati na podacima u ```data/occupancy_test.csv```.\n",
    "\n",
    "* Konstruisati i obučiti neuronsku mrežu na problemu linearne regresije sa prvih vežbi (stopa smrtnosti od raka kože u odnosu na geografsku širinu).\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
