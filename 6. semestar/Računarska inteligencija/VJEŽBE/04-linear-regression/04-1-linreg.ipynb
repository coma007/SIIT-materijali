{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Osnovi računarske inteligencije\n",
    "\n",
    "## Vežba 4.1 - Linearna regresija\n",
    "\n",
    "---\n",
    "\n",
    "### Jednostavna linearna regresija\n",
    "\n",
    "Jednostavna linearna regresija je statistički metod koji omogućava proučavanje veze između dve\n",
    "kontinualne promenljive.\n",
    "\n",
    "Prva promenljiva, **x**, se naziva prediktor ili **nezavisna promeljiva**.\n",
    "\n",
    "Druga promenljiva, **y** se naziva odziv ili **zavisna promenljiva**.\n",
    "\n",
    "Jednostavna linearna regresija ima pridev \"jednostavna\" zato što ima samo jednu nezavisnu promenljivu (x).\n",
    "Postoji i višestruka linearna regresija, koja se odnosni na linearnu regresiju sa više nezavisnih promenljivih.\n",
    "\n",
    "Pre opisa same linearne regresije, važno je napomenuti kakve veze/zavisnosti između promenljivih su od interesa.\n",
    "\n",
    "---\n",
    "\n",
    "**Deterministička (funkcionalna) zavisnost** nam nije od interesa jer njom možemo odrediti **tačnu** vrednost zavisne promenljive (y) na osnovu vrednosti nezavise promenljive (x). Primer ovakve veze je, recimo, konvertovanje mernih\n",
    "jedinica temperature između stepeni Celzijusa i Farenhajta:\n",
    "\n",
    "$$\n",
    "\\text{Fahr} = \\frac{9}{5} * \\text{Cels} + 32\n",
    "$$\n",
    "\n",
    "![](img/celcius_fahr_plot.gif)\n",
    "\n",
    "Znajući temperaturu u stepenima Celzijusa, možemo iskoristiti prethodnu jednačinu da **tačno** odredimo temperaturu u Farenhajtima. Još neki primeri determinističke zavisnosti su:\n",
    "\n",
    "* $ \\text{obim} = 2 \\pi * \\text{poluprecnik} $\n",
    "* Omov zakon: $ \\text{I} = \\frac{V}{R} $\n",
    "* Hukov zakon: $ \\text{F} = -\\text{k}\\text{x} $\n",
    "\n",
    "---\n",
    "\n",
    "Za svaku od ovih determinističkih zavisnosti, jednačina tačno opisuje odnos dve promenljive. Ne razmatramo determinističke veze, već  **statističku zavisnost**, gde veza između dve promenljive nije savršeno tačna.\n",
    "\n",
    "Primer statističke zavisnosti je određivanje stope smrtnosti od raka kože (broj smrti na 10 miliona ljudi) na osnovu geografske širine centra svake od 49 država u SAD ([skincancer.csv](data/skincancer.csv))\n",
    "\n",
    "Može se pretpostaviti da u zemljama koje su severnije, ljudi su manje izloženi sunčevoj svetlosti i štetnim uticajima sunčevih zraka (UV zračenja) i samim tim bi rizik smrti od raka kože trebao biti manji. Dole prikazani grafik podržava takvu hipotezu - vidi se negativna linerna zavisnost između geografske širine i stope smrtnosti od raka kože, ali ova veza nije savršeno linearna. Dakle, ovo je statistička zavisnost, a ne deterministička.\n",
    "\n",
    "![](img/scatterplot_skin_cancer.png)\n",
    "\n",
    "Još neki primeri statističke zavisnosti mogu biti:\n",
    "\n",
    "* Visina i težina ljudi - uglavnom očekujemo da su više osobe teže, ali ne mora nužno biti tako\n",
    "* Kapacitet pluća i količina konzumiranih cigara tokom života - kako se količina konzumiranih cigara povećava, očekuje se smanjenje kapaciteta pluća\n",
    "* Broj ljudi u prostoriji i temperatura/vlažnost prostorije\n",
    "* Količina uloženog truda tokom studiranja (kako ovo izmeriti?) i prolaznost / prosek ocena\n",
    "\n",
    "---\n",
    "\n",
    "##### Koja je \"najpogodnija linija\"?\n",
    "\n",
    "Pošto je neophodno pronaći neku linearu zavisnost između dve promenljive, nameće se pitanje koja je to najpogodnija linija koji opisuje tu zavisnost? U principu, zanima nas da pronađemo liniju $ \\hat{y} = a + bx $ koja na najbolji način opisuje date podatke. Podaci su dati kao:\n",
    "\n",
    "* $ x_i $ - vrednost nezavisne promenljive za svako merenje *i*\n",
    "* $ y_i $ - vrednost zavisne promenljive za svako merenje *i*\n",
    "* $ \\hat{y}_i $ - vrednost *predviđene* zavisne promenljive za svako merenje *i*\n",
    "\n",
    "Očigledno je da će se $ y_i $ i $ \\hat{y}_i $ razlikovati u određenoj meri (u nekim merenjima manje u nekim merenjima više), ali je potrebno *u proseku* smanjiti ovu razliku. Jednostavna linearna regresija je postupak koji pronalazi najpogodniju liniju koja opisuje zadate podatke $ x_i $ i $ y_i $, minimizujući grešku predikcije $ e_i = y_i - \\hat{y}_i $.\n",
    "\n",
    "---\n",
    "\n",
    "##### Izvođenje linearne regresije\n",
    "\n",
    "Linija koja najbolje \"fituje\" (od eng. *fit* - pristajati) podatke će biti ona linija za koje su **n grešaka predikcije** - za svako merenje - **male koliko god je moguće u nekom opštem smislu**. Jedan način za postizanje ovog cilja je **metod najmanjih kvadrata**, koja kaže da se treba *minimizovati suma kvadrata grešaka predikcije*. Odnosno:\n",
    "\n",
    "* Jednačina linije koja najbolje \"fituje\" je $ \\hat{y} = a + bx $ - *a* je odsečak na y-osi, a *b* je nagib linije\n",
    "* Potrebno je odrediti vrednosti *a* i *b* koje će činiti da je suma kvadratnih grešaka predikcije što je moguće manja\n",
    "* Dakle, potrebno je pronaći *a* i *b* koji minimizuju: $$ Q=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2 = \\sum_{i=1}^{n}(y_i-a-bx_i)^2 $$\n",
    "\n",
    "\n",
    "Kako bismo pronašli *a* i *b* koje minimizuju *Q*, pronaći ćemo parcijalne izvode (seća li se iko?) od *Q* u odnosu na *a* i *b* i izjednačiti ih sa nulom, i rešiti ih za *a* i *b*:\n",
    "$$\n",
    "\\frac{\\partial Q}{\\partial a} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial Q}{\\partial b} = 0\n",
    "$$\n",
    "\n",
    "Rešenje:\n",
    "$$\n",
    "a = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-bx_i) = \\bar{y} - b\\bar{x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = \\frac{\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y})}{\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2}=\\frac{Cov(x,y)}{Var(x)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "##### Zadaci\n",
    "\n",
    "**TODO 1**: Implementirati jednostavu linearnu regresiju. Ulazi parametri su liste/vektori *x* i *y*, koji predstavljaju podatke, a povratne vrednosti su *slope* i *intercept* koji predstavlju nagib i presečnu tačku linije koja najbolje \"fituje\" podatke. Fajl `src/linreg_simple.py` -> funkcija `fit(x, y)`.\n",
    "\n",
    "**TODO 2**: Implementirati predviđanje vrednosti y na osnovu jednog podatka x koristeci nagib i presek. Fajl `src/linreg_simple.py` -> funkcija `predict(x, slope, intercept)`.\n",
    "\n",
    "**TODO 3**: Izvršiti linearnu regresiju na primeru predviđanja stope smrtnosti od raka kože na osnovu geografske širine američkih država.\n",
    "* Učitati datoteku *data/skincancer.csv* i implementirati primenu linearne regresije u Python fajlu ```src/skin_cancer.py```.\n",
    "* Iscrati grafik za ovaj slučaj.\n",
    "* Probati linearnu regresiju nad ovim istim skupom podataka, ali da se umesto geografske širine koristi geografska dužina.\n",
    "---\n",
    "\n",
    "### Višestruka linearna regresija\n",
    "\n",
    "Za razliku od jednostavne linearne regresije koja koristi samo jednu prediktorsku promenljivu *x*, višestruka linearna regresija podrazumeva korišćenje dve ili više prediktorskih promenljivih. Na prethodnom primeru, mogli bismo dodati: kako zavisi stopa smrtnosti od raka kože u odnosu na geografsku širinu države **i** cene kreme za sunčanje, prosečne plate, klime?\n",
    "\n",
    "Višestruka linearna regresija je odličan alat za otkrivanje interesantnih zavisnosti između podataka, koje možda nisu nisu očigledne na prvi pogled.\n",
    "\n",
    "U opštem obliku, višestruka linearna regresija podrazumeva jednačinu:\n",
    "$ \\hat{y} = a + b_1x_1 + b_2x_2 + ... + b_px_p $, gde je neophodno pronaći parametre *a* i *b* na isti način kao kod jednostavne linearne regresije - minimizacijom sume kvadratnih grešaka predikcije $ Q=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2 $.\n",
    "\n",
    "---\n",
    "\n",
    "#### Python biblioteka scikit-learn\n",
    "**scikit-learn** (http://scikit-learn.org/) je open-source Python biblioteka, koja predstavlja jednostavan i efikasan alat za mašinsko učenje i analizu podataka. Ova biblioteka sadrži implementiran **ogroman** broj raznih algoritama i postupaka i primera za njihovu primenu.\n",
    "\n",
    "---\n",
    "\n",
    "##### Zadaci\n",
    "\n",
    "**TODO 4**: Iskoristiti scikit-learn alat za primenu višestruke linearne regresije nad podacima iz datoteke *data/iq.tsv* u fajlu ```src/iq.py```. Ova datoteka sadrži podatke o 38 osoba za koje je izmerena zapremina mozga, visina i težina, kao i koeficijent inteligencije (IQ). Potrebno je proceniti koliko fizičke karakteristike utiču na IQ.\n",
    "* Proučiti dokumentaciju za linearnu regresiju u scikit-learn biblioteci, pogledati primere.\n",
    "* Nakon primene višestruke linearne regresije nad ovim podacima, protumačiti dobijene \"fitovane\" parametre - kako visina utiče na IQ, kako veličina mozga utiče na IQ, kako težina utiče na IQ?\n",
    "\n",
    "**DODATNO**: Pogledati zbirku raznih podataka pogodnih za analizu pomoću linearne regresije:\n",
    "* http://www.stat.ufl.edu/~winner/datasets.html - sekcija **LR 1a**\n",
    "* http://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html - sekcija **Datasets**\n",
    "\n",
    "---\n",
    "\n",
    "##### Domaći\n",
    "\n",
    "Razmisliti:\n",
    "* Koje su prednosti linearne regresije?\n",
    "* Koja su ograničenja linearne regresije?\n",
    "* Šta raditi u slučaju kada podaci nisu kontinualni, nego diskretni?\n",
    "* Šta raditi u slučaju kada je potrebna binarna klasifikacija? (npr. na osnovu finanskijskih podataka treba odlučiti da li banka da dozvoli kredit ili ne - 1 ili 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
