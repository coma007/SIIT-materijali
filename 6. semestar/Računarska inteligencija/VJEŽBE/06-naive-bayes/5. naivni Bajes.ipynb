{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naivni Bajes\n",
    "<p>\n",
    "<img style=\"float:right; max-width:400px\" src=\"imgs/spam filter.gif\" width=\"40%\" />\n",
    "\n",
    "Naivni Bajes (*Naive Bayes*) je jedan od najpoznatijih klasifikacionih algoritama u ML.\n",
    "\n",
    "Ulaz u algoritam je podatak, a izlaz je neka klasa (npr. spam ili nije spam).\n",
    "Cilj algoritma je da izračuna verovatnoću da neki podatak pripada nekoj klasi (npr. verovatnoća da li je mejl spam je 91%, a da nije spam 9%).\n",
    "Naivni Bajes se često koristi u klasifikaciji teksta, što ćemo i prikazati u nastavku.\n",
    "\n",
    "Spada u algoritme nadgedanog učenja. Nadgledano učenje znači da obučavamo model tako što na ulaz algoritma dovedemo gomilu podataka i odgovarajuće klase. Za svaki podatak se tačno zna kojoj klasi pripada. Algoritam uči iz podataka. \n",
    "\n",
    "Algoritam se zove *naivni* jer pretpostavlja da su osobine međusobno **nezavisne** u odnosu na ciljnu klasu.\n",
    "Naivni Bajes se zasniva na Bajesovoj teoremi.\n",
    "</p>\n",
    "\n",
    "## Bajesova teorema\n",
    "Opisuje verovatnoću nekog događaja na osnovu drugih događaja koji ga uslovljavaju.\n",
    "$$ P(A|B) = {P(A) P(B|A)  \\over P(B)} $$\n",
    "\n",
    "- $P(A)$ i $P(B)$ su verovatnoće događaja $A$ i $B$. \n",
    "- $P(A|B)$ je verovatnoća događaja A, ako se desio događaj B\n",
    "- $P(B|A)$ je verovatnoća događaja B, ako se desio događaj A\n",
    "- U literaturi se često nalaze oznake $H$ i $E$ umesto $A$ i $B$, gde je $H$ je skraćeno od *Hypothesis*, a $E$ je skraćeno od *Evidence*.\n",
    "\n",
    "*Komentar: Bajesova teorema ne pretpostavlja nezavisnost događaja A i B, za razliku od Naivnog Bajesa.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vremenska prognoza\n",
    "<p>\n",
    "<img style=\"float:right; max-width:300px\" src=\"imgs/weather-icon.webp\" width=\"40%\" />\n",
    "\n",
    "Želimo da procenimo verovatnoću da će danas padati kiša na osnovu podataka vremenske prognoze.\n",
    "\n",
    "*Napomena: Prognoza je prosta i razlikuje samo 2 stanja: 1. kišne i 2. suncane dane. Nema snega, oblaka itd.*\n",
    "\n",
    "Danas želimo da odemo u šetnju, ali ne znamo da li će padati kiša i da li nam treba kišobran?\n",
    "Pogledamo sajt vremenske prognoze gde piše da će danas padati kiša. Na sajtu prognoze tvrde da su 90% tačni: od 10 kišnih dana, predvideli su 9 kišnih dana. \n",
    "Takođe tvrde da su 80% tačni kada predviđaju sunčane dane. Izgleda da je vremenska prognoza prilično pouzadana.\n",
    "\n",
    "**Da li to znači da je verovatnoća da će danas padati kiša = 90%?** \n",
    "\n",
    "**Da li treba da ponesemo kišobran u šetnju?**\n",
    "\n",
    "Izgleda da je vremenska prognoza prilično pouzdana, pa odlučimo da ćemo danas da prošetamo sa kišobranom. Ispostavi se da je ceo dan bio sunčan! ☀️ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zašto smo promašili u proceni?\n",
    "Promašili smo u proceni jer nismo sve sagledali: nismo uzeli u obzir činjenicu da **ima mnogo više sunčanih dana!**\n",
    "\n",
    "Zaključak je da nam treba nam još informacija za tačnu procenu.\n",
    "Iz [skupa podataka](forecast.csv) vidimo da imamo podatke za prethodnih 100 dana:\n",
    "\n",
    "- Od ukupno 100 dana, ima samo 10 kišnih dana.\n",
    "- Od ukupno 100 dana, ima čak  90 sunčanih dana (Na 9 sunčanih dana, dođe tek 1 kišni dan).\n",
    "- Od tih 10 kišnih dana (levo na slici), prognoza je pogodila 9 puta, a 1 put promašila (jednom je prognoza predvidela kišu, kada je zapravo sijalo sunce).\n",
    "- Od 90 sunčanih dana, prognoza je 18 puta promašila (predvidela kišu, kada je zapravo sijalo sunce), a 72 puta je pogodila.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"imgs/forecast 1.png\" style='width:90%; max-width:50rem'/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $P(kiša | prognoza \\ predvidi \\ kišu) = ?$\n",
    "Mi znamo da je prognoza predviđa kišu za danas. Znamo i da je prognoza pogodila 9 od 10 kišnih dana, tj. 90%.\n",
    "\n",
    "Formalnije zapisano: $P(prognoza \\ predvidi \\ kišu | kiša ) = 90 \\%$\n",
    "\n",
    "**Ako je prognoza predvidela danas kišu, ne znači da je verovatnoća za kišu = 90%!**\n",
    "\n",
    "**$P(kiša | prognoza \\ predvidi \\ kišu)$ nije isto što i $P(prognoza \\ predvidi \\ kišu | kiša) = 90\\%$!**\n",
    " \n",
    "- Označimo sa *H (Hypothesis)* da stvarno pada kiša. Označimo sa *E (Evidence)* da prognoza predviđa kišu.\n",
    "- Pitamo se $ P(H|E) = ? \\%$\n",
    "- Znamo da je prognoza od 10 kišnih dana uspešno pogodila 9, pa je $P(E|H) = 90\\%$. \n",
    "- Obratite paznju da $P(E|H)$ i $P(H|E)$ nisu iste stvari.\n",
    "- Znamo da je prognoza pogodila sunčan dan 72 puta od 90 dana, pa je $ P(\\neg E|\\neg H) = 80\\% $.\n",
    "- Znamo da je prognoza promašila sunčan dan 18 puta od 90 dana, pa je $ P(E|\\neg H) = 20\\% $.\n",
    "\n",
    "#### Kako da izračunamo $P(H|E)$? \n",
    "\n",
    "Setimo se Bajesove formule: \n",
    "$P(H|E) = {P(H) P(E|H)  \\over P(E)}$\n",
    "\n",
    "Vidmo da nam fali: \n",
    "1. $P(H)$ - verovatnoća da pada kiša. - Od 100 dana koliko je bilo kišnih dana? Vidimo da ima samo 10 kišnih dana, pa je $P(H) = 10\\%$.\n",
    "2. $P(E)$ - verovatnoća da je prognoza predvidela da pada kiša. - Od 100 dana koliko je puta prognoza rekla da pada kiša? Tu se računa i kada prognoza tačno predvidi kišu, ali i kada pogreši (predvidi kišu, a zapravo sija sunce). Vidimo da je prognoza predvidela kišu 9 + 18 = 27 puta, pa je $P(E) = 27\\%$.\n",
    "\n",
    "Dobijene vrednosti uvrstimo u Bajesovu formulu i dobijamo:\n",
    "$$P(H|E) = {P(H) P(E|H)  \\over P(E)} = {10\\% * 90\\%  \\over 27\\%} = 33\\% $$\n",
    "\n",
    "<p style=\"color:salmon; font-weight:bold\"> Ispada da je verovatnoća da pada kiša, ako prognoza predvidi kišu samo 33%. Razlog je što ima mnogo više sunčanih dana od kišnih dana.</p>\n",
    "Pokazali smo da prethodna statistika kojom se vremenska prognoza hvali i nije baš toliko impresivna :)\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"imgs/forecast 2.png\" style='width:90%; max-width:50rem'/>\n",
    "</div>\n",
    "\n",
    "Da rezimiramo:\n",
    "- $H$ - stvarno pada kiša, $E$ - prognoza predviđa kišu\n",
    "- $ P(H) = 10 \\% $ - 10 kišnih dana od ukupno 100 dana\n",
    "- $ P(E) = 27\\% $ prognoza je predvidela kišu 27 dana od ukupno 100 dana. Tu se računa i kada prognoza tačno predvidi kišu, ali i kada pogreši (predvidi kišu, a zapravo sija sunce).\n",
    "- $ P(E|H) = 90\\% $ -  od 10 kišnih dana, prognoza je predvidela 9 kišnih dana\n",
    "- $P(H|E) = {P(H) P(E|H)  \\over P(E)} = {10\\% * 90\\%  \\over 27\\%} = 33\\% $\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naivni Bajes klasifikator u kodu\n",
    "Učimo NB klasifikator da predvidi verovatnoću da pada kiša, ako prognoza kaže da danas pada kiša. Želimo u kodu da dobijemo iste rezultate koje smo matematički izračunali koristeći Bajesovu formulu.\n",
    "\n",
    "Kako da naučimo klasifikator da zna da je baš 33% verovatnoća da pada kiša, ako je kišni dan?\n",
    "Klasifikator učimo tako što:\n",
    "1. prosledimo [podatke](forecast.csv),\n",
    "1. pozovemo metodu `fit()`,\n",
    "1. pozovemo metodu `predict_proba()`.\n",
    "\n",
    "*Da biste uspešno pokrenuli notebook trebaju vam biblioteke: numpy, pandas, scikit-learn. Instalirajte ih ručno ili izvršite `pip install -r requirements.txt` u konzoli, kako biste instalirali neophodne biblioteke.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67933976 0.32066024]\n",
      "P(sunce| prognoza predvidi kišu) = 67.93%\n",
      "P(kiša | prognoza predvidi kišu) = 32.07%\n"
     ]
    }
   ],
   "source": [
    "# ------- 1. prosledimo podatke -------\n",
    "# ucitamo fajl\n",
    "import pandas as pd\n",
    "df = pd.read_csv('forecast.csv') \n",
    "\n",
    "# klasifikatoru trebaju brojevi, a ne reci 'rainy' i 'sunny' iz skupa podataka\n",
    "# umesto 'sunny' se piše 0, umesto 'rainy' se piše 1\n",
    "df['Weather Condition'] = df['Weather Condition'].factorize()[0]\n",
    "df = pd.get_dummies(df, columns=['Forecast Predicts Rain'])\n",
    "\n",
    "# niz x koji sadrzi sve osobine (features), a y ciljnu klasu (target)\n",
    "x = df.drop(columns=['Weather Condition']).values\n",
    "y = df['Weather Condition'].values\n",
    "\n",
    "# ------- 2. pozovemo metodu `fit()` -------\n",
    "# ------- obučimo klasifikator -------------\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0.5)\n",
    "clf.fit(x, y)\n",
    "\n",
    "# --- 3. pozovemo metodu `predict_proba()` ---\n",
    "# Rezultat obučavanja: ako prognoza predvidi kišu, \n",
    "# koja je verovatnoća da će pasti kiša? Očekujemo ~ 33% što smo izračunali sa Bajesovom Formulom.\n",
    "forecast_predicts_rain = [0,1]\n",
    "p_h_e = clf.predict_proba([forecast_predicts_rain])[0]\n",
    "print(p_h_e)\n",
    "print(f'P(sunce| prognoza predvidi kišu) = {p_h_e[0] * 100:.2f}%')\n",
    "print(f'P(kiša | prognoza predvidi kišu) = {p_h_e[1]*100:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidimo da je $P(H|E)$ oko 33% što smo i očekivali. Konkretna vrednost verovatnoće zavisi od hiper-parametera klasifikatora. (U kasnijim lekcijama će biti više reči o hiper-pametrima)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes vs Gaussian Naive Bayes\n",
    "\n",
    "<p>\n",
    "<img style=\"float:right; max-width:300px\" src=\"imgs/petal and sepal.jpeg\" width=\"40%\" />\n",
    "\n",
    "Verdnosti mogu biti diskretne ili kontinualne.\n",
    "Do sada smo radili sa diskretnim vrednostima: vreme je bilo: **kišno** ili **sunčano**. Prognozno je **pogodila** ili **nije pogodila** vremenske uslove. \n",
    "Šta kada imamo kontinualne vrednosti: **vlažnost vazduha, temperatura u toku dana, količina padavina**,...\n",
    "Idalje možemo da koristimo Naivni Bajes klasifikator kao i do sad. Ipak, ako podaci prate Gausovu distribuciju, onda će *uglavnom* bolje rezultati imati *Gaussian Naive Bayes*.\n",
    "\n",
    "Hajde da pogledamo sledeći primer sa kontinualnim vrednostima: **želimo da klasifikujemo cveće**.\n",
    "<br>\n",
    "Svaki cvet je opisan sa 4 osobine: *sepal length, sepal width, petal length, petal width*. Na slici desno vidimo šta je *sepal*, a šta je *petal*.\n",
    "Ciljne klase su: *setosa, versicolor, i virginica.*\n",
    "Želimo da na osnovu date 4 osobine procenimo da li je neki cvet *setosa, versicolor, ili virginica.*\n",
    "\n",
    "Videćemo da idalje možemo da koristimo Naivni Bajes koji će biti 90% tačan, ali će *Gaussian Naive Bayes* biti 94% tačan.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = load_iris() # učitamo skup podataka\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.7, random_state=42)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train) # obučimo klasifikator\n",
    "\n",
    "y_pred = clf.predict(x_test) # prediktujemo vrednosti\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred) # izračunamo tačnost\n",
    "print(f\"Accuracy: {accuracy*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "iris = load_iris() # učitamo skup podataka\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.7, random_state=42)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train) # obučimo klasifikator\n",
    "\n",
    "y_pred = clf.predict(x_test) # prediktujemo vrednosti\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred) # izračunamo tačnost\n",
    "print(f\"Accuracy: {accuracy*100:.0f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<p>\n",
    "<img style=\"float:right; max-width:500px\" src=\"imgs/sentiment.png\" width=\"40%\" />\n",
    "\n",
    "## Naivni Bajes kao klasifikator teksta\n",
    "Naivni Bajes smo do sad upotrebili kao klasifikator nad vrlo jednostavnim podacima. U nastavku je dat primer kako se NB koristi za klasifikaciju teksta.\n",
    "\n",
    "Dat nam je skup podataka koji sadrži tekst recenzije i sentiment. Sentiment svake recenzije je ✅ pozitivan ili ❌ negativan. Radimo binarnu klasifikaciju jer u skupu podataka imamo dve klase: **pos** i **neg** koje označavaju pozitivnu i negativnu recenziju.\n",
    "\n",
    "- Primer ✅ pozitivne recenzije: *The movie was great!*\n",
    "- Primer ❌ negativne recenzija: *The acting was terrible*\n",
    "\n",
    "Cilj: Naučimo NB klasifikator da klasifikuje recenzije na ✅ pozitivne i ❌ negativne.\n",
    "Ucimo NB klasifikator da odredi:\n",
    "- $P( ✅ | recenzija) = ?$ - verovatnoća da je sentiment pozitivan za datu recenziju i \n",
    "- $P( ❌ | recenzija) = ?$ - verovatnoća da je sentiment negativan za datu recenziju.\n",
    "\n",
    "Kada imamo obe verovatnoće prosto ih uporedimo i uzmemo klasu sa vecom verovatnoćom. Na primer:\n",
    "Za tekst nove recenzije *The movie was great!* izracunamo da je  \n",
    "$$ P( ✅ | The \\ movie \\ was \\ great!)  > P( ❌ | The \\ movie \\ was \\ great!) $$\n",
    "Pa znamo da je *The movie was great!* pozitivna recenzija.\n",
    "<p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The movie was great', 'That was the greatest movie!', 'I really enjoyed that great movie.', 'The acting was terrible', 'The movie was not great at all...']\n"
     ]
    }
   ],
   "source": [
    "reviews = {\n",
    "    'The movie was great': 'pos',\n",
    "    'That was the greatest movie!': 'pos',\n",
    "    'I really enjoyed that great movie.': 'pos',\n",
    "    'The acting was terrible': 'neg',\n",
    "    'The movie was not great at all...': 'neg'}\n",
    "print(list(reviews.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kako odrediti sentiment recenzije?\n",
    "Tekst recenzije podelimo na reči. Recenziju posmatramo kao skup reči. Za svaku reč gledamo da li se češće nalazi u ✅ ili ❌ recenzijama.\n",
    "Ideja je da se neke reči više ponavljaju u ✅ recenzijama (*great, happy,..*), a neke reči više u ❌ (*hate, terrible,...*). \n",
    "NB klasifikator zapravo uči verovatnoću za svaku reč da se pojavi u ✅ recenziji i ❌ recenziji. Npr učimo: $P(great|✅)$ i $P(great|❌ )$.\n",
    "Kada za svaku reč iz recenzije znamo verovatnoću, onda lako izračunamo verovatnoću da cela recenzija (skup reči) pripada nekoj klasi.\n",
    "\n",
    "NB klasifikator zanemaruje redosled reči u recenziji. Recenzija se posmatra kao skup reči. Redosled reči nije bitan. Da li to ima smisla za prirodni jezik? - Nema, jer je redosled reči bitan u svakom jeziku. Ipak, ispostavi se da skup reči (bez redosleda) daje odlične rezultate.\n",
    "Reprezentacija teksta koja zanemaruje redosled reči naziva se *Bag-of-words*.\n",
    "\n",
    "<p>\n",
    "<img style=\"float:right; max-width:500px\" src=\"imgs/bow.png\" width=\"40%\" />\n",
    "\n",
    "### *Bag-of-words* \n",
    "Skraceno BOW, ili još \"vreća reči\" - jednostavna reprezentacija teksta koja zanemaruje redosled reči. Postupak:\n",
    "- Zamislimo da čitamo neki tekst na papiru.\n",
    "- Svaku reč iz teksta isečemo makazama, tako da je na svakom papiriću samo jedna reč. \n",
    "- Sve isečene reči/papiriće ubacimo u \"vreću reči\".\n",
    "- Protresemo vreću.\n",
    "- Iz vreće izvadimo sve reči i prebrojimo koliko se puta svaka reč pojavila u vreći.\n",
    "- Napravimo tabelu ponavaljanja reči.\n",
    "\n",
    "*Napomena: Kada bismo uveli redosled reči u recenici, dobili bi minimalno poboljsanje i mnogo komplikovaniji kod, pa se u praksi izbacuje redosled reči u recenici.*\n",
    "</p>\n",
    "\n",
    "##### *Bag-of-words* u kodu\n",
    "Neke reči se više ponavljaju u ✅ recenzijama, a neke u ❌. S toga nam treba tabela ponavljanja reči. Pravimo 2 tabele ponavaljanja reči:  1. tabela ponavljanja reči u ✅ recenzijama i 2. tabela ponavljanja reči u ❌ recenzijama. Ove tabele u *Python*-u su 2 rečnika (`dict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'was': 2,\n",
       " 'great': 2,\n",
       " 'The': 1,\n",
       " 'movie': 1,\n",
       " 'That': 1,\n",
       " 'the': 1,\n",
       " 'greatest': 1,\n",
       " 'movie!': 1,\n",
       " 'I': 1,\n",
       " 'really': 1,\n",
       " 'enjoyed': 1,\n",
       " 'that': 1,\n",
       " 'movie.': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_word_counts, neg_word_counts = {}, {}\n",
    "\n",
    "for review, sentiment in reviews.items():\n",
    "    words = review.split() # recenziju podelimo u reči\n",
    "    for word in words: \n",
    "        if sentiment == 'pos': pos_word_counts[word] = pos_word_counts.get(word, 0) + 1\n",
    "        if sentiment == 'neg': neg_word_counts[word] = neg_word_counts.get(word, 0) + 1\n",
    "\n",
    "dict(sorted(pos_word_counts.items(), key=lambda x: x[1], reverse=True)) # broj ponavaljanja u ✅"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nailazimo na problem da se reči: *the* i *The* posmatraju kao dve reči, iako su to suštinski dve iste reči. Sličan problem je i za: *great!* i *great*. To nije dobro. Treba da uklonimo razliku između velikih i malih slova, kao i znakove interpunkcije.\n",
    "Postupak sređivanja podataka zovemo **pretprocesiranje podataka**. Što bolje pretprocesiramo podatke, dobićemo bolje rezultate. Postoje razne tehnike pretprocesiranja o kojima ćemo kasnije govoriti.\n",
    "Za sad ćemo uraditi jednostavno pretprocsiranje: svesti sva slova na mala i ukloniti znakove interpunkcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pos_word_counts, neg_word_counts \u001b[39m=\u001b[39m {}, {} \u001b[39m# init counts\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m review, sentiment \u001b[39min\u001b[39;00m reviews\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     review \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, review) \u001b[39m# uklonimo znakove\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     words \u001b[39m=\u001b[39m review\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39msplit() \u001b[39m# svedemo na mala slova i podelimo na reči\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pos_word_counts, neg_word_counts = {}, {} # init counts\n",
    "\n",
    "for review, sentiment in reviews.items():\n",
    "    review = re.sub(r'[^\\w\\s]', '', review) # uklonimo znakove\n",
    "    words = review.lower().split() # svedemo na mala slova i podelimo na reči\n",
    "    for word in words: \n",
    "        if sentiment == 'pos': pos_word_counts[word] = pos_word_counts.get(word, 0) + 1\n",
    "        if sentiment == 'neg': neg_word_counts[word] = neg_word_counts.get(word, 0) + 1\n",
    "\n",
    "dict(sorted(pos_word_counts.items(), key=lambda x: x[1], reverse=True)) # broj ponavaljanja u ✅"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $P( ✅ | recenzija)$ VS $P( ❌ | recenzija)$\n",
    "\n",
    "Da bismo odredili da li je neka recenzija pozitivna ili negativna, treba da izracunamo $P( ✅ | recenzija)$ i $P( ❌ | recenzija)$. \n",
    "Kada imamo ove dve verovatnoće, treba da ih uporedimo i odaberemo klasu sa većom verovatnoćom. Npr. ako je $P( ✅ | recenzija) > P( ❌ | recenzija)$, onda je recenzija pozitivna. \n",
    "\n",
    "Uopšteno, tražimo verovatnoću sentimenta $s_i$ za dati tekst $T$, tj.  tražimo $P(s_i|T)$. Po Bajesovoj formuli dobijamo da je:\n",
    "$$P(s_i|T) = {P(s_i) P(T|s_i)  \\over P(T)} = ?$$\n",
    "\n",
    "$P(T)$ je konstanta, nezavisno od toga da li je sentiment ✅ ili ❌. Setimo se da treba samo da uporedimo verovatnoće $P( ✅ | recenzija)$ i $P( ❌ | recenzija)$. Zbog toga $P(T)$ možemo da izbacimo iz formule. Tehnički, više nemamo tačne verovatnoće (u rasponu 0% - 100%) već dobijamo broj proporcionalan verovatnoći. Dobijamo:\n",
    "$$P(s_i|T) \\propto {P(s_i) P(T|s_i)}$$\n",
    "Ostaje nam da odredimo 1. $P(s_i)$ i 2. $P(T|s_i)$.\n",
    "\n",
    "1. $P(s_i) $ je verovatnoća sentimenta $s_i$. Npr. $P(✅)$ je verovatnoća da se pojavi pozitivna recenzija. $P(✅)$ je broj pozitvnih recenzija od ukupnog broja recenzija (✅ + ❌)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m review_counts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m} \u001b[39m# broj ✅ recenzija i broj ❌ recenzija\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m review, sentiment \u001b[39min\u001b[39;00m reviews\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m sentiment \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m: review_counts[\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[39melif\u001b[39;00m sentiment \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m'\u001b[39m: review_counts[\u001b[39m'\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews' is not defined"
     ]
    }
   ],
   "source": [
    "review_counts = {'pos': 0, 'neg': 0} # broj ✅ recenzija i broj ❌ recenzija\n",
    "for review, sentiment in reviews.items():\n",
    "    if sentiment == 'pos': review_counts['pos'] += 1\n",
    "    elif sentiment == 'neg': review_counts['neg'] +=1\n",
    "\n",
    "prior = {'pos': 0, 'neg': 0} # P(✅) i P(❌)\n",
    "n_total_reviews = sum(review_counts.values())\n",
    "prior['pos'] = review_counts['pos'] / n_total_reviews\n",
    "prior['neg'] = review_counts['neg'] / n_total_reviews\n",
    "\n",
    "prior['pos'], prior['neg']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Početna verovatnoća da je recenzija ✅ je 60%, a ❌ je 40%. Očekujemo te rezultate jer u skupu podataka imamo 3 pozivitne i 2 negativne recenzije.\n",
    "Odredili smo $P(s_i)$. Ostaje da odredimo $P(T|s_i)$.\n",
    "\n",
    "2. $P(T|s_i)$ je verovatnoća teksta za sentiment. Tekst $T$ je neka recenzija filma. Setimo se da je tekst vreća reči koja zanemaruje redlosed. Zbog toga tekst $T$ podelimo na reči $t \\in T$ i dobijamo:\n",
    "$P(T) = P(t_1) \\cdot P(t_2) \\cdot ... \\cdot P(t_n) =  \\prod_{t \\in T} P(t)$ \n",
    "\n",
    "Npr. za recenziju *the movie was great* dobijamo: $P(the \\ movie \\ was \\ great| ✅) = P(the| ✅) \\cdot P(movie| ✅) \\cdot P(was| ✅) \\cdot P(great| ✅)$\n",
    "\n",
    "<!-- Citamo: Verovatnoća da se rec *the* nadje u pozitivnoj recenziji, puta verovatnoća da se rec *movie* nadje u pozitivnoj recenici,... -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verovatnoća da se reč nađe u pozitivnoj recenziji:\n",
      "P(the|✅) = 0.13, P(movie|✅) = 0.20, P(was|✅) = 0.13, P(great|✅) = 0.13, "
     ]
    }
   ],
   "source": [
    "text = 'The movie was great'\n",
    "text = re.sub(r'[^\\w\\s]', '', text) # uklonimo znakove\n",
    "words = text.lower().split() # svedemo na mala slova i podelimo na reči\n",
    "\n",
    "n_words = {'pos': 0, 'neg': 0} # ukupan broj ✅ reči i ukupan broj ❌ reči\n",
    "n_words['pos'] = sum(pos_word_counts.values())\n",
    "p_words_given_pos = []\n",
    "\n",
    "for word in words:    \n",
    "    p_word_given_pos = pos_word_counts.get(word, 0) / n_words['pos'] # e.g. P(movie|pos)\n",
    "    p_words_given_pos.append(p_word_given_pos) # add to list of probabilities\n",
    "\n",
    "print('Verovatnoća da se reč nađe u pozitivnoj recenziji:')\n",
    "for p, w in zip(p_words_given_pos, words):\n",
    "    print(f'P({w}|✅) = {p:.2f}', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verovatnoća da se reč nađe u negativnoj recenziji:\n",
      "P(the|❌) = 0.18, P(movie|❌) = 0.09, P(was|❌) = 0.18, P(great|❌) = 0.09, "
     ]
    }
   ],
   "source": [
    "n_words['neg'] = sum(neg_word_counts.values())\n",
    "p_words_given_neg = []\n",
    "for word in words:\n",
    "    p_word_given_neg = neg_word_counts.get(word, 0) / n_words['neg'] # e.g. P(movie|neg)\n",
    "    p_words_given_neg.append(p_word_given_neg) # add to list of probabilities\n",
    "\n",
    "print('Verovatnoća da se reč nađe u negativnoj recenziji:')\n",
    "for p, w in zip(p_words_given_neg, words):\n",
    "    print(f'P({w}|❌) = {p:.2f}', end=', ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(The movie was great|✅) = 0.00047\n",
      "P(The movie was great|❌) = 0.00027\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "p_text_given_pos = np.prod(p_words_given_pos)\n",
    "print(f'P({text}|✅) = {p_text_given_pos:.5f}')\n",
    "\n",
    "p_text_given_neg = np.prod(p_words_given_neg)\n",
    "print(f'P({text}|❌) = {p_text_given_neg:.5f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odredili smo 1. $P(s_i)$ i 2. $P(T|s_i)$ Ove vrednosti uvrstimo nazad u formulu: $P(s_i|T) = {P(s_i) P(T|s_i)} $ kako bismo klasifikovali recenziju *The movie was great*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(✅|The movie was great) = 0.00028\n",
      "P(❌|The movie was great) = 0.00011\n",
      "Recenzija je pozitivna\n"
     ]
    }
   ],
   "source": [
    "p_text_is_pos = prior['pos'] * p_text_given_pos\n",
    "p_text_is_neg = prior['neg'] * p_text_given_neg\n",
    "\n",
    "print(f'P(✅|{text}) = {p_text_is_pos:.5f}')\n",
    "print(f'P(❌|{text}) = {p_text_is_neg:.5f}')\n",
    "\n",
    "if p_text_is_pos > p_text_is_neg: print('Recenzija je pozitivna')\n",
    "else: print('Recenzija je negativna')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Laplace Smoothing*\n",
    "\n",
    "U recenziji *The movie was great* su sve reči bile zastupljene u rečnicima ✅ i ❌ recenija (`pos_word_counts`, `neg_word_counts`).\n",
    "\n",
    "Sada klasifikujemo novu recenziju *The movie was terrible, terrible, terrible,...*\n",
    "\n",
    "Kao i do sad treba da odredimo 1. $P(s_i)$ i 2. $P(T|s_i)$.\n",
    "Već smo izračunali $P(s_i)$ u promenljivama `prior['pos']` i  `prior['neg']`.\n",
    "Fali nam 2. $P(T|s_i)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mThe movie was terrible, terrible, terrible,...\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text) \u001b[39m# uklonimo znakove\u001b[39;00m\n\u001b[1;32m      3\u001b[0m words \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39msplit() \u001b[39m# svedemo na mala slova i podelimo na reči\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# verovatnoća da se reč nađe u pozitivnoj recenziji\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "text = 'The movie was terrible, terrible, terrible,...'\n",
    "text = re.sub(r'[^\\w\\s]', '', text) # uklonimo znakove\n",
    "words = text.lower().split() # svedemo na mala slova i podelimo na reči\n",
    "\n",
    "# verovatnoća da se reč nađe u pozitivnoj recenziji\n",
    "n_pos_words = sum(pos_word_counts.values())\n",
    "p_words_given_pos = []\n",
    "for word in words:    \n",
    "    p_word_given_pos = pos_word_counts.get(word, 0) / n_pos_words\n",
    "    p_words_given_pos.append(p_word_given_pos)\n",
    "\n",
    "for p, w in zip(p_words_given_pos, words):\n",
    "    print(f'P({w}|✅) = {p:.2f}', end=', ')\n",
    "\n",
    "\n",
    "# verovatnoća da se reč nađe u negativnoj recenziji\n",
    "n_neg_words = sum(neg_word_counts.values())\n",
    "p_words_given_neg = []\n",
    "for word in words:\n",
    "    p_word_given_neg = neg_word_counts.get(word, 0) / n_neg_words\n",
    "    p_words_given_neg.append(p_word_given_neg)\n",
    "\n",
    "print()\n",
    "for p, w in zip(p_words_given_neg, words):\n",
    "    print(f'P({w}|❌) = {p:.2f}', end=', ')\n",
    "\n",
    "print('\\n-----')\n",
    "p_text_given_pos = np.prod(p_words_given_pos)\n",
    "print(f'P({text}|✅) = {p_text_given_pos}')\n",
    "p_text_given_neg = np.prod(p_words_given_neg)\n",
    "print(f'P({text}|❌) = {p_text_given_neg}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nailazimo na problem da je $P(terrible|✅) = 0$ jer reč *terrible* nikad nije viđena u pozitivnoj recenziji. \n",
    "<br>\n",
    "Ovo je loše jer da bi izračunali $P(text| ✅)$ treba da množimo verovatnoće. Nula pomnoženo sa bilo čim je idalje nula. \n",
    "<br>\n",
    "**Ako nikad nismo videli neku reč, verovatnoća $P(text| ✅)$ je automatski nula!** To ne želimo. Želimo neku verovatnoću različitu od nule. Da bismo dobili broj različit od nule, broj ponavljanja svake reči povećamo za 1. Ovaj postupak zove se *Laplace Smoothing*. Time smo sigurni da kada vidimo nepoznatu reč, verovatnoća neće automatski biti nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(the|✅) = 2.04, P(movie|✅) = 3.04, P(was|✅) = 2.04, P(terrible|✅) = 0.04, P(terrible|✅) = 0.04, P(terrible|✅) = 0.04, \n",
      "P(the|❌) = 2.05, P(movie|❌) = 1.05, P(was|❌) = 2.05, P(terrible|❌) = 1.05, P(terrible|❌) = 1.05, P(terrible|❌) = 1.05, \n",
      "-----\n",
      "P(The movie was terrible terrible terrible|✅) = 0.0009171652041672022\n",
      "P(The movie was terrible terrible terrible|❌) = 5.108165015625\n"
     ]
    }
   ],
   "source": [
    "text = 'The movie was terrible, terrible, terrible,...'\n",
    "text = re.sub(r'[^\\w\\s]', '', text) # uklonimo znakove\n",
    "words = text.lower().split() # svedemo na mala slova i podelimo na reči\n",
    "\n",
    "# verovatnoća da se reč nađe u pozitivnoj recenziji\n",
    "n_pos_words = sum(pos_word_counts.values())\n",
    "p_words_given_pos = []\n",
    "for word in words:    \n",
    "    p_word_given_pos = pos_word_counts.get(word, 0) + 1 / (n_pos_words + len(pos_word_counts)) # Laplace Smoothing\n",
    "    p_words_given_pos.append(p_word_given_pos)\n",
    "\n",
    "for p, w in zip(p_words_given_pos, words):\n",
    "    print(f'P({w}|✅) = {p:.2f}', end=', ')\n",
    "\n",
    "\n",
    "# verovatnoća da se reč nađe u negativnoj recenziji\n",
    "n_neg_words = sum(neg_word_counts.values())\n",
    "p_words_given_neg = []\n",
    "for word in words:\n",
    "    p_word_given_neg = neg_word_counts.get(word, 0) + 1 / (n_neg_words + len(neg_word_counts)) # Laplace Smoothing\n",
    "    p_words_given_neg.append(p_word_given_neg)\n",
    "\n",
    "print()\n",
    "for p, w in zip(p_words_given_neg, words):\n",
    "    print(f'P({w}|❌) = {p:.2f}', end=', ')\n",
    "\n",
    "print('\\n-----')\n",
    "p_text_given_pos = np.prod(p_words_given_pos)\n",
    "print(f'P({text}|✅) = {p_text_given_pos}')\n",
    "p_text_given_neg = np.prod(p_words_given_neg)\n",
    "print(f'P({text}|❌) = {p_text_given_neg}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uspešno smo dobili $P(text|✅) \\neq 0$, pa sada možemo da klasifikujemo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "P(✅|The movie was terrible terrible terrible) = 0.00055\n",
      "P(❌|The movie was terrible terrible terrible) = 2.04327\n",
      "Recenzija je negativna\n"
     ]
    }
   ],
   "source": [
    "# klasifikacija\n",
    "print('-----')\n",
    "p_text_is_pos = prior['pos'] * p_text_given_pos\n",
    "p_text_is_neg = prior['neg'] * p_text_given_neg\n",
    "print(f'P(✅|{text}) = {p_text_is_pos:.5f}')\n",
    "print(f'P(❌|{text}) = {p_text_is_neg:.5f}')\n",
    "if p_text_is_pos > p_text_is_neg: print('Recenzija je pozitivna')\n",
    "else: print('Recenzija je negativna')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadaci\n",
    "1. Implementirati NaiveBayes klasu do kraja u fajlu: 5. Naivni Bajes.py.\n",
    "\n",
    "\n",
    "## Dodatni zadaci:\n",
    "1. Istražiti i implementirati tokenizaciju: znakovi interpunkcije, *stop-words , stemming, lematization*.\n",
    "1. Log funkcija - Postoji problem kod mnozenja verovatnoća reči. Kada množimo mnogo brojeva manjih od nula, verovatnoća će biti priblizno nula, ili prouzrokovati underflow.\n",
    "Zbog toga treba logaritmovati ceo izraz. Na taj način proizvod se pretvara u sumu.\n",
    "\n",
    "1. Dat je [skup podataka](reviews.tsv) koji sadrži tekst recenzije filmova i knjiga. Sentiment svake recenzije može biti pozitivan i negativan. Radimo binarnu klasifikaciju jer u nasem skupu podataka imamo samo dve klase: **pos** i **neg** koje označavaju pozitivnu i negativnu recenziju.\n",
    "*Napomena: skup podataka nije cenzurisan i mozda sadrži uvredljive recenzije.*\n",
    "Zadatak: Naučiti NB klasifikator da klasifikuje recenzije na pozitivne i negativne.\n",
    "\n",
    "1. Iskoristiti scikit-learn biblioteku da se obuči klasifikator nad [skupom podataka](reviews.tsv)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
